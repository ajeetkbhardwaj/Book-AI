{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d882d2",
   "metadata": {},
   "source": [
    "How to apply transformers in text, image, video, audio and time series etc\n",
    "\n",
    "Transformer model \n",
    "- A backbone architecture to represent and extract information from a sequence of embeddings of discrete tokens.\n",
    "- It takes input of shape (seq_lenght, embedd_size) and outputs tensors of identical shapes\n",
    "- Ex-1 : Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a1cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f57d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, ffn_size, num_heads=2, dropout=0.2):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        # multi-head attention\n",
    "        self.mhattn = nn.MultiheadAttention(\n",
    "            embed_dim = embed_dim,\n",
    "            num_heads = num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # 2. Feed Forward NN\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ffn_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ffn_size, embed_dim)\n",
    "        )\n",
    "        # 3. Layer normalization\n",
    "        self.input_ln = nn.LayerNorm(embed_dim)\n",
    "        self.ffn_ln = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # forward pass over the input data x\n",
    "        def forward(self, x):\n",
    "            y = self.input_ln(x)\n",
    "            y, _ = self.mhattn(y, y, y),\n",
    "            y += x\n",
    "\n",
    "            z = self.ffn_ln(y)\n",
    "            z = self.ffn(z)\n",
    "            z += y\n",
    "\n",
    "            return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeaadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 img_dim,\n",
    "                 num_patches,\n",
    "                 num_classes,\n",
    "                 embed_dim,\n",
    "                 ffn_size,\n",
    "                 num_heads,\n",
    "                 dropout,\n",
    "                 num_blocks):\n",
    "        super(VisionTransformer, self).__init__()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
